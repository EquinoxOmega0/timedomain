{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from desispec.io import read_spectra\n",
    "from desitrip.preproc import rebin_flux, rescale_flux\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rc('font', size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Spectra\n",
    "\n",
    "Input DESI spectra, rebin and rescale them, and then divide them into training and test sets for the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_spectra(input_files):\n",
    "    \"\"\"Read DESI spectra, rebin to a subsampled logarithmic wavelength grid, and rescale.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_files : list or ndarray\n",
    "        List of FITS files on disk with DESI spectra.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    fluxes : ndarray\n",
    "        Array of fluxes rebinned to a logarithmic wavelength grid.\n",
    "    \"\"\"\n",
    "    fluxes = None\n",
    "    \n",
    "    for f in input_files:\n",
    "        spectra = read_spectra(host_files[0])\n",
    "        wave = spectra.wave['brz']\n",
    "        flux = spectra.flux['brz']\n",
    "        ivar = spectra.ivar['brz']\n",
    "\n",
    "        # Pre-condition: remove spectra with NaNs and zero flux values.\n",
    "        mask = np.isnan(flux).any(axis=1) | (np.count_nonzero(flux, axis=1) == 0)\n",
    "        mask_idx = np.argwhere(mask)\n",
    "        flux = np.delete(flux, mask_idx, axis=0)\n",
    "        ivar = np.delete(ivar, mask_idx, axis=0)\n",
    "\n",
    "        # Rebin and rescale fluxes so that each is normalized between 0 and 1.\n",
    "        rewave, reflux, reivar = rebin_flux(wave, flux, ivar, minwave=3600., maxwave=9800., nbins=400, log=True)\n",
    "        rsflux = rescale_flux(reflux)\n",
    "\n",
    "        if fluxes is None:\n",
    "            fluxes = rsflux\n",
    "        else:\n",
    "            fluxes = np.concatenate((fluxes, rsflux))\n",
    "    \n",
    "    return fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_files = sorted(glob('../../../../bgs/150s/hosts/*coadd.fits'))\n",
    "host_flux  = condition_spectra(host_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "snia_files = sorted(glob('../../../../bgs/150s/sn_ia/hsiao/*coadd.fits'))\n",
    "snia_flux  = condition_spectra(snia_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000, 400)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nhost, nbins = host_flux.shape\n",
    "nsnia, nbins = snia_flux.shape\n",
    "\n",
    "nhost, nsnia, nbins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Training Sets and Labels\n",
    "\n",
    "0. \"host\" spectra based only on BGS templates\n",
    "1. \"snia\" spectra based on BGS + SN Ia templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate([host_flux, snia_flux]).reshape(-1, nbins, 1)\n",
    "y = np.concatenate([np.zeros(nhost), np.ones(nsnia)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Network Setup\n",
    "\n",
    "Train network with TensorFlow+Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import utils, regularizers, callbacks, backend\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, ZeroPadding1D, BatchNormalization, Flatten, Reshape, Conv1D, MaxPooling1D, Dropout, Add, LSTM, Embedding\n",
    "from tensorflow.keras.initializers import glorot_normal, glorot_uniform\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(input_shape, learning_rate=0.0005, reg=0.0032, dropout=0.7436, seed=None):\n",
    "    \"\"\"Define the CNN structure.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_shape : int\n",
    "        Shape of the input spectra.\n",
    "    learning_rate : float\n",
    "        Learning rate.\n",
    "    reg : float\n",
    "        Regularization factor.\n",
    "    dropout : float\n",
    "        Dropout rate.\n",
    "    seed : int\n",
    "        Seed of initializer.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    model : tensorflow.keras.Model\n",
    "        A model instance of the network.\n",
    "    \"\"\"\n",
    "    X_input = Input(input_shape, name='Input_Spec')\n",
    "    \n",
    "    X_input = Input(input_shape, name='Input_Spec')\n",
    "\n",
    "    # First convolutional layer.\n",
    "    with backend.name_scope('Conv_1'):\n",
    "        X = Conv1D(filters=8, kernel_size=5, strides=1, padding='same',\n",
    "                   kernel_regularizer=regularizers.l2(reg),\n",
    "                   bias_initializer='zeros',\n",
    "                   kernel_initializer=glorot_normal(seed))(X_input)\n",
    "        X = BatchNormalization(axis=2)(X)\n",
    "        X = Activation('relu')(X)\n",
    "        X = MaxPooling1D(pool_size= 2)(X)\n",
    "\n",
    "    # Second convolutional layer.\n",
    "    with backend.name_scope('Conv_2'):\n",
    "        X = Conv1D(filters=16, kernel_size=5, strides=1, padding='same',\n",
    "                   kernel_regularizer=regularizers.l2(reg),\n",
    "                   bias_initializer='zeros',\n",
    "                   kernel_initializer=glorot_normal(seed))(X)\n",
    "        X = BatchNormalization(axis=2)(X)\n",
    "        X = Activation('relu')(X)\n",
    "        X = MaxPooling1D(2)(X)\n",
    "        \n",
    "    # Third convolutional layer.\n",
    "    with backend.name_scope('Conv_3'):\n",
    "        X = Conv1D(filters=32, kernel_size=5, strides=1, padding='same',\n",
    "                   kernel_regularizer=regularizers.l2(reg),\n",
    "                   bias_initializer='zeros',\n",
    "                   kernel_initializer=glorot_normal(seed))(X)\n",
    "        X = BatchNormalization(axis=2)(X)\n",
    "        X = Activation('relu')(X)\n",
    "        X = MaxPooling1D(2)(X)\n",
    "        \n",
    "    # Fourth convolutional layer.\n",
    "    with backend.name_scope('Conv_4'):\n",
    "        X = Conv1D(filters=64, kernel_size=5, strides=1, padding='same',\n",
    "                   kernel_regularizer=regularizers.l2(reg),\n",
    "                   bias_initializer='zeros',\n",
    "                   kernel_initializer=glorot_normal(seed))(X)\n",
    "        X = BatchNormalization(axis=2)(X)\n",
    "        X = Activation('relu')(X)\n",
    "        X = MaxPooling1D(2)(X)\n",
    "\n",
    "    # Flatten to fully connected dense layer.\n",
    "    with backend.name_scope('Dense_Layer'):\n",
    "        X = Flatten()(X)\n",
    "        X = Dense(256, kernel_regularizer=regularizers.l2(reg),\n",
    "                  activation='relu')(X)\n",
    "        X = Dropout(rate=dropout, seed=seed)(X)\n",
    "    \n",
    "    # Output layer with sigmoid activation.\n",
    "    with backend.name_scope('Output_Layer'):\n",
    "        X = Dense(1, kernel_regularizer=regularizers.l2(reg),\n",
    "              activation='sigmoid',name='Output_Classes')(X)\n",
    "\n",
    "    model = Model(inputs=X_input, outputs=X, name='SNnet')\n",
    "    \n",
    "    # Set up optimizer, loss function, and optimization metrics.\n",
    "    model.compile(optimizer=Adam(lr=learning_rate), loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7436 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "model = network((nbins, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Large dropout rate: 0.7436 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7436 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "15000/15000 [==============================] - 17s 1ms/sample - loss: 1.7287 - accuracy: 0.5003 - val_loss: 1.3191 - val_accuracy: 0.4942\n",
      "Epoch 2/50\n",
      "15000/15000 [==============================] - 14s 904us/sample - loss: 1.1480 - accuracy: 0.5039 - val_loss: 1.0172 - val_accuracy: 0.4950\n",
      "Epoch 3/50\n",
      "15000/15000 [==============================] - 14s 910us/sample - loss: 0.9433 - accuracy: 0.4980 - val_loss: 0.8826 - val_accuracy: 0.4934\n",
      "Epoch 4/50\n",
      "15000/15000 [==============================] - 14s 912us/sample - loss: 0.8452 - accuracy: 0.5029 - val_loss: 0.8126 - val_accuracy: 0.5052\n",
      "Epoch 5/50\n",
      "15000/15000 [==============================] - 14s 922us/sample - loss: 0.7906 - accuracy: 0.4978 - val_loss: 0.7709 - val_accuracy: 0.5050\n",
      "Epoch 6/50\n",
      "15000/15000 [==============================] - 14s 916us/sample - loss: 0.7575 - accuracy: 0.4979 - val_loss: 0.7445 - val_accuracy: 0.5058\n",
      "Epoch 7/50\n",
      "15000/15000 [==============================] - 14s 918us/sample - loss: 0.7351 - accuracy: 0.4974 - val_loss: 0.7269 - val_accuracy: 0.4932\n",
      "Epoch 8/50\n",
      "15000/15000 [==============================] - 14s 910us/sample - loss: 0.7225 - accuracy: 0.4984 - val_loss: 0.7162 - val_accuracy: 0.4942\n",
      "Epoch 9/50\n",
      "15000/15000 [==============================] - 14s 920us/sample - loss: 0.7122 - accuracy: 0.5028 - val_loss: 0.7084 - val_accuracy: 0.4942\n",
      "Epoch 10/50\n",
      "15000/15000 [==============================] - 14s 918us/sample - loss: 0.7059 - accuracy: 0.5023 - val_loss: 0.7034 - val_accuracy: 0.4942\n",
      "Epoch 11/50\n",
      "15000/15000 [==============================] - 14s 930us/sample - loss: 0.7013 - accuracy: 0.5019 - val_loss: 0.6997 - val_accuracy: 0.4942\n",
      "Epoch 12/50\n",
      "15000/15000 [==============================] - 14s 941us/sample - loss: 0.7009 - accuracy: 0.5043 - val_loss: 0.7003 - val_accuracy: 0.4942\n",
      "Epoch 13/50\n",
      "15000/15000 [==============================] - 15s 971us/sample - loss: 0.6976 - accuracy: 0.5016 - val_loss: 0.6963 - val_accuracy: 0.4942\n",
      "Epoch 14/50\n",
      "15000/15000 [==============================] - 14s 956us/sample - loss: 0.6956 - accuracy: 0.4993 - val_loss: 0.6952 - val_accuracy: 0.4942\n",
      "Epoch 15/50\n",
      "15000/15000 [==============================] - 14s 932us/sample - loss: 0.6948 - accuracy: 0.4985 - val_loss: 0.6945 - val_accuracy: 0.4942\n",
      "Epoch 16/50\n",
      "15000/15000 [==============================] - 14s 932us/sample - loss: 0.6943 - accuracy: 0.5019 - val_loss: 0.6941 - val_accuracy: 0.4942\n",
      "Epoch 17/50\n",
      "15000/15000 [==============================] - 14s 938us/sample - loss: 0.6939 - accuracy: 0.5019 - val_loss: 0.6939 - val_accuracy: 0.4942\n",
      "Epoch 18/50\n",
      "15000/15000 [==============================] - 14s 939us/sample - loss: 0.6937 - accuracy: 0.5019 - val_loss: 0.6937 - val_accuracy: 0.4942\n",
      "Epoch 19/50\n",
      "15000/15000 [==============================] - 14s 945us/sample - loss: 0.6936 - accuracy: 0.5019 - val_loss: 0.6936 - val_accuracy: 0.4942\n",
      "Epoch 20/50\n",
      "15000/15000 [==============================] - 14s 939us/sample - loss: 0.6935 - accuracy: 0.5019 - val_loss: 0.6934 - val_accuracy: 0.4942\n",
      "Epoch 21/50\n",
      "15000/15000 [==============================] - 14s 948us/sample - loss: 0.6934 - accuracy: 0.5019 - val_loss: 0.6934 - val_accuracy: 0.4942\n",
      "Epoch 22/50\n",
      "15000/15000 [==============================] - 14s 951us/sample - loss: 0.6933 - accuracy: 0.5019 - val_loss: 0.6933 - val_accuracy: 0.4942\n",
      "Epoch 23/50\n",
      "15000/15000 [==============================] - 14s 928us/sample - loss: 0.6933 - accuracy: 0.5019 - val_loss: 0.6933 - val_accuracy: 0.4942\n",
      "Epoch 24/50\n",
      "15000/15000 [==============================] - 14s 928us/sample - loss: 0.6932 - accuracy: 0.5019 - val_loss: 0.6933 - val_accuracy: 0.4942\n",
      "Epoch 25/50\n",
      "15000/15000 [==============================] - 14s 939us/sample - loss: 0.6932 - accuracy: 0.5019 - val_loss: 0.6933 - val_accuracy: 0.4942\n",
      "Epoch 26/50\n",
      "15000/15000 [==============================] - 14s 925us/sample - loss: 0.6932 - accuracy: 0.5019 - val_loss: 0.6932 - val_accuracy: 0.4942\n",
      "Epoch 27/50\n",
      "15000/15000 [==============================] - 14s 922us/sample - loss: 0.6932 - accuracy: 0.5019 - val_loss: 0.6932 - val_accuracy: 0.4942\n",
      "Epoch 28/50\n",
      "15000/15000 [==============================] - 14s 931us/sample - loss: 0.6932 - accuracy: 0.5019 - val_loss: 0.6932 - val_accuracy: 0.4942\n",
      "Epoch 29/50\n",
      "15000/15000 [==============================] - 14s 921us/sample - loss: 0.6932 - accuracy: 0.5019 - val_loss: 0.6932 - val_accuracy: 0.4942\n",
      "Epoch 30/50\n",
      "15000/15000 [==============================] - 14s 923us/sample - loss: 0.6932 - accuracy: 0.4991 - val_loss: 0.6932 - val_accuracy: 0.4942\n",
      "Epoch 31/50\n",
      "15000/15000 [==============================] - 14s 924us/sample - loss: 0.6932 - accuracy: 0.5019 - val_loss: 0.6932 - val_accuracy: 0.4942\n",
      "Epoch 32/50\n",
      "15000/15000 [==============================] - 14s 924us/sample - loss: 0.6932 - accuracy: 0.5019 - val_loss: 0.6932 - val_accuracy: 0.4942\n",
      "Epoch 33/50\n",
      "15000/15000 [==============================] - 14s 906us/sample - loss: 0.6931 - accuracy: 0.5019 - val_loss: 0.6932 - val_accuracy: 0.4942\n",
      "Epoch 34/50\n",
      "15000/15000 [==============================] - 14s 915us/sample - loss: 0.6932 - accuracy: 0.4999 - val_loss: 0.6932 - val_accuracy: 0.4942\n",
      "Epoch 35/50\n",
      "15000/15000 [==============================] - 14s 921us/sample - loss: 0.6932 - accuracy: 0.5019 - val_loss: 0.6932 - val_accuracy: 0.4942\n",
      "Epoch 36/50\n",
      "15000/15000 [==============================] - 14s 921us/sample - loss: 0.6931 - accuracy: 0.5019 - val_loss: 0.6932 - val_accuracy: 0.4942\n",
      "Epoch 37/50\n",
      "15000/15000 [==============================] - 14s 938us/sample - loss: 0.6932 - accuracy: 0.5019 - val_loss: 0.6932 - val_accuracy: 0.4942\n",
      "Epoch 38/50\n",
      "15000/15000 [==============================] - 15s 969us/sample - loss: 0.6932 - accuracy: 0.5019 - val_loss: 0.6932 - val_accuracy: 0.4942\n",
      "Epoch 39/50\n",
      "15000/15000 [==============================] - 14s 958us/sample - loss: 0.6932 - accuracy: 0.5019 - val_loss: 0.6932 - val_accuracy: 0.4942\n",
      "Epoch 40/50\n",
      "15000/15000 [==============================] - 14s 941us/sample - loss: 0.6932 - accuracy: 0.5019 - val_loss: 0.6932 - val_accuracy: 0.4942\n",
      "Epoch 41/50\n",
      "15000/15000 [==============================] - 15s 976us/sample - loss: 0.6932 - accuracy: 0.5019 - val_loss: 0.6932 - val_accuracy: 0.4942\n",
      "Epoch 42/50\n",
      "15000/15000 [==============================] - 14s 947us/sample - loss: 0.6932 - accuracy: 0.5019 - val_loss: 0.6932 - val_accuracy: 0.4942\n",
      "Epoch 43/50\n",
      "15000/15000 [==============================] - 14s 920us/sample - loss: 0.6932 - accuracy: 0.5019 - val_loss: 0.6932 - val_accuracy: 0.4942\n",
      "Epoch 44/50\n",
      "15000/15000 [==============================] - 14s 920us/sample - loss: 0.6932 - accuracy: 0.5019 - val_loss: 0.6932 - val_accuracy: 0.4942\n",
      "Epoch 45/50\n",
      "15000/15000 [==============================] - 14s 923us/sample - loss: 0.6931 - accuracy: 0.5019 - val_loss: 0.6932 - val_accuracy: 0.4942\n",
      "Epoch 46/50\n",
      "15000/15000 [==============================] - 14s 934us/sample - loss: 0.6932 - accuracy: 0.5019 - val_loss: 0.6932 - val_accuracy: 0.4942\n",
      "Epoch 47/50\n",
      "15000/15000 [==============================] - 14s 946us/sample - loss: 0.6931 - accuracy: 0.5019 - val_loss: 0.6932 - val_accuracy: 0.4942\n",
      "Epoch 48/50\n",
      "15000/15000 [==============================] - 14s 927us/sample - loss: 0.6931 - accuracy: 0.5019 - val_loss: 0.6932 - val_accuracy: 0.4942\n",
      "Epoch 49/50\n",
      "15000/15000 [==============================] - 14s 921us/sample - loss: 0.6932 - accuracy: 0.5019 - val_loss: 0.6932 - val_accuracy: 0.4942\n",
      "Epoch 50/50\n",
      "15000/15000 [==============================] - 14s 945us/sample - loss: 0.6932 - accuracy: 0.5019 - val_loss: 0.6932 - val_accuracy: 0.4942\n"
     ]
    }
   ],
   "source": [
    "permute = np.random.permutation(len(y))\n",
    "l = len(x)\n",
    "hist = model.fit(x[permute][:l], y[permute][:l], batch_size=64, epochs=50, validation_split=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:desi] *",
   "language": "python",
   "name": "conda-env-desi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
