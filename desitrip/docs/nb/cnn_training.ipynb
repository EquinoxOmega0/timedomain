{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from desispec.io import read_spectra\n",
    "from desitrip.preproc import rebin_flux, rescale_flux\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rc('font', size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Spectra\n",
    "\n",
    "Input DESI spectra, rebin and rescale them, and then divide them into training and test sets for the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_spectra(input_files):\n",
    "    \"\"\"Read DESI spectra, rebin to a subsampled logarithmic wavelength grid, and rescale.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_files : list or ndarray\n",
    "        List of FITS files on disk with DESI spectra.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    fluxes : ndarray\n",
    "        Array of fluxes rebinned to a logarithmic wavelength grid.\n",
    "    \"\"\"\n",
    "    fluxes = None\n",
    "    \n",
    "    for f in input_files:\n",
    "        spectra = read_spectra(f)\n",
    "        wave = spectra.wave['brz']\n",
    "        flux = spectra.flux['brz']\n",
    "        ivar = spectra.ivar['brz']\n",
    "\n",
    "        # Pre-condition: remove spectra with NaNs and zero flux values.\n",
    "        mask = np.isnan(flux).any(axis=1) | (np.count_nonzero(flux, axis=1) == 0)\n",
    "        mask_idx = np.argwhere(mask)\n",
    "        flux = np.delete(flux, mask_idx, axis=0)\n",
    "        ivar = np.delete(ivar, mask_idx, axis=0)\n",
    "\n",
    "        # Rebin and rescale fluxes so that each is normalized between 0 and 1.\n",
    "        rewave, reflux, reivar = rebin_flux(wave, flux, ivar, minwave=3600., maxwave=9800., nbins=600, log=True)\n",
    "        rsflux = rescale_flux(reflux)\n",
    "\n",
    "        if fluxes is None:\n",
    "            fluxes = rsflux\n",
    "        else:\n",
    "            fluxes = np.concatenate((fluxes, rsflux))\n",
    "    \n",
    "    return fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_truth = sorted(glob('../../../../bgs/150s/hosts/*truth.fits'))\n",
    "host_coadd = sorted(glob('../../../../bgs/150s/hosts/*coadd.fits'))\n",
    "host_flux  = condition_spectra(host_coadd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "snia_truth = sorted(glob('../../../../bgs/150s/sn_ia/hsiao/*truth.fits'))\n",
    "snia_files = sorted(glob('../../../../bgs/150s/sn_ia/hsiao/*coadd.fits'))\n",
    "snia_flux  = condition_spectra(snia_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9969, 9964, 600)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nhost, nbins = host_flux.shape\n",
    "nsnia, nbins = snia_flux.shape\n",
    "\n",
    "nhost, nsnia, nbins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Training Sets and Labels\n",
    "\n",
    "0. \"host\" spectra based only on BGS templates\n",
    "1. \"snia\" spectra based on BGS + SN Ia templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate([host_flux, snia_flux]).reshape(-1, nbins, 1)\n",
    "y = np.concatenate([np.zeros(nhost), np.ones(nsnia)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Network Setup\n",
    "\n",
    "Train network with TensorFlow+Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import utils, regularizers, callbacks, backend\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, ZeroPadding1D, BatchNormalization, Flatten, Reshape, Conv1D, MaxPooling1D, Dropout, Add, LSTM, Embedding\n",
    "from tensorflow.keras.initializers import glorot_normal, glorot_uniform\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(input_shape, learning_rate=0.0005, reg=0.0032, dropout=0.7436, seed=None):\n",
    "    \"\"\"Define the CNN structure.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_shape : int\n",
    "        Shape of the input spectra.\n",
    "    learning_rate : float\n",
    "        Learning rate.\n",
    "    reg : float\n",
    "        Regularization factor.\n",
    "    dropout : float\n",
    "        Dropout rate.\n",
    "    seed : int\n",
    "        Seed of initializer.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    model : tensorflow.keras.Model\n",
    "        A model instance of the network.\n",
    "    \"\"\"\n",
    "    X_input = Input(input_shape, name='Input_Spec')\n",
    "    \n",
    "    X_input = Input(input_shape, name='Input_Spec')\n",
    "\n",
    "    # First convolutional layer.\n",
    "    with backend.name_scope('Conv_1'):\n",
    "        X = Conv1D(filters=8, kernel_size=5, strides=1, padding='same',\n",
    "                   kernel_regularizer=regularizers.l2(reg),\n",
    "                   bias_initializer='zeros',\n",
    "                   kernel_initializer=glorot_normal(seed))(X_input)\n",
    "        X = BatchNormalization(axis=2)(X)\n",
    "        X = Activation('relu')(X)\n",
    "        X = MaxPooling1D(pool_size= 2)(X)\n",
    "\n",
    "    # Second convolutional layer.\n",
    "    with backend.name_scope('Conv_2'):\n",
    "        X = Conv1D(filters=16, kernel_size=5, strides=1, padding='same',\n",
    "                   kernel_regularizer=regularizers.l2(reg),\n",
    "                   bias_initializer='zeros',\n",
    "                   kernel_initializer=glorot_normal(seed))(X)\n",
    "        X = BatchNormalization(axis=2)(X)\n",
    "        X = Activation('relu')(X)\n",
    "        X = MaxPooling1D(2)(X)\n",
    "        \n",
    "    # Third convolutional layer.\n",
    "    with backend.name_scope('Conv_3'):\n",
    "        X = Conv1D(filters=32, kernel_size=5, strides=1, padding='same',\n",
    "                   kernel_regularizer=regularizers.l2(reg),\n",
    "                   bias_initializer='zeros',\n",
    "                   kernel_initializer=glorot_normal(seed))(X)\n",
    "        X = BatchNormalization(axis=2)(X)\n",
    "        X = Activation('relu')(X)\n",
    "        X = MaxPooling1D(2)(X)\n",
    "        \n",
    "    # Fourth convolutional layer.\n",
    "    with backend.name_scope('Conv_4'):\n",
    "        X = Conv1D(filters=64, kernel_size=5, strides=1, padding='same',\n",
    "                   kernel_regularizer=regularizers.l2(reg),\n",
    "                   bias_initializer='zeros',\n",
    "                   kernel_initializer=glorot_normal(seed))(X)\n",
    "        X = BatchNormalization(axis=2)(X)\n",
    "        X = Activation('relu')(X)\n",
    "        X = MaxPooling1D(2)(X)\n",
    "\n",
    "    # Flatten to fully connected dense layer.\n",
    "    with backend.name_scope('Dense_Layer'):\n",
    "        X = Flatten()(X)\n",
    "        X = Dense(256, kernel_regularizer=regularizers.l2(reg),\n",
    "                  activation='relu')(X)\n",
    "        X = Dropout(rate=dropout, seed=seed)(X)\n",
    "    \n",
    "    # Output layer with sigmoid activation.\n",
    "    with backend.name_scope('Output_Layer'):\n",
    "        X = Dense(1, kernel_regularizer=regularizers.l2(reg),\n",
    "              activation='sigmoid',name='Output_Classes')(X)\n",
    "\n",
    "    model = Model(inputs=X_input, outputs=X, name='SNnet')\n",
    "    \n",
    "    # Set up optimizer, loss function, and optimization metrics.\n",
    "    model.compile(optimizer=Adam(lr=learning_rate), loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7436 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "model = network((nbins, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14949 samples, validate on 4984 samples\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Large dropout rate: 0.7436 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7436 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "14949/14949 [==============================] - 21s 1ms/sample - loss: 1.7575 - accuracy: 0.5871 - val_loss: 1.3735 - val_accuracy: 0.5546\n",
      "Epoch 2/50\n",
      "14949/14949 [==============================] - 18s 1ms/sample - loss: 1.1598 - accuracy: 0.6330 - val_loss: 1.0221 - val_accuracy: 0.6298\n",
      "Epoch 3/50\n",
      "14949/14949 [==============================] - 18s 1ms/sample - loss: 0.9364 - accuracy: 0.6588 - val_loss: 0.8444 - val_accuracy: 0.7020\n",
      "Epoch 4/50\n",
      "14949/14949 [==============================] - 18s 1ms/sample - loss: 0.8227 - accuracy: 0.6702 - val_loss: 0.7612 - val_accuracy: 0.6956\n",
      "Epoch 5/50\n",
      "14949/14949 [==============================] - 18s 1ms/sample - loss: 0.7447 - accuracy: 0.6990 - val_loss: 0.6941 - val_accuracy: 0.7327\n",
      "Epoch 6/50\n",
      "14949/14949 [==============================] - 18s 1ms/sample - loss: 0.6939 - accuracy: 0.7132 - val_loss: 0.6747 - val_accuracy: 0.7069\n",
      "Epoch 7/50\n",
      "14949/14949 [==============================] - 18s 1ms/sample - loss: 0.6595 - accuracy: 0.7292 - val_loss: 0.6269 - val_accuracy: 0.7482\n",
      "Epoch 8/50\n",
      "14949/14949 [==============================] - 18s 1ms/sample - loss: 0.6279 - accuracy: 0.7413 - val_loss: 0.6867 - val_accuracy: 0.7004\n",
      "Epoch 9/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.6037 - accuracy: 0.7584 - val_loss: 0.6482 - val_accuracy: 0.7241\n",
      "Epoch 10/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.5793 - accuracy: 0.7746 - val_loss: 0.7712 - val_accuracy: 0.6591\n",
      "Epoch 11/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.5636 - accuracy: 0.7809 - val_loss: 0.5598 - val_accuracy: 0.7817\n",
      "Epoch 12/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.5462 - accuracy: 0.7950 - val_loss: 0.5997 - val_accuracy: 0.7490\n",
      "Epoch 13/50\n",
      "14949/14949 [==============================] - 20s 1ms/sample - loss: 0.5264 - accuracy: 0.8057 - val_loss: 0.5582 - val_accuracy: 0.7899\n",
      "Epoch 14/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.5205 - accuracy: 0.8096 - val_loss: 0.5652 - val_accuracy: 0.7781\n",
      "Epoch 15/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.5104 - accuracy: 0.8177 - val_loss: 0.6100 - val_accuracy: 0.7350\n",
      "Epoch 16/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.4910 - accuracy: 0.8296 - val_loss: 0.5777 - val_accuracy: 0.7719\n",
      "Epoch 17/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.4798 - accuracy: 0.8352 - val_loss: 0.7120 - val_accuracy: 0.7159\n",
      "Epoch 18/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.4728 - accuracy: 0.8403 - val_loss: 0.5522 - val_accuracy: 0.7917\n",
      "Epoch 19/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.4638 - accuracy: 0.8442 - val_loss: 0.6448 - val_accuracy: 0.7448\n",
      "Epoch 20/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.4478 - accuracy: 0.8551 - val_loss: 0.5839 - val_accuracy: 0.7869\n",
      "Epoch 21/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.4347 - accuracy: 0.8644 - val_loss: 0.5846 - val_accuracy: 0.7753\n",
      "Epoch 22/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.4289 - accuracy: 0.8668 - val_loss: 0.5828 - val_accuracy: 0.7851\n",
      "Epoch 23/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.4172 - accuracy: 0.8750 - val_loss: 0.6455 - val_accuracy: 0.7640\n",
      "Epoch 24/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.4185 - accuracy: 0.8748 - val_loss: 0.6318 - val_accuracy: 0.7707\n",
      "Epoch 25/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.4011 - accuracy: 0.8843 - val_loss: 0.6616 - val_accuracy: 0.7622\n",
      "Epoch 26/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.4032 - accuracy: 0.8833 - val_loss: 0.6805 - val_accuracy: 0.7663\n",
      "Epoch 27/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.3930 - accuracy: 0.8889 - val_loss: 0.6377 - val_accuracy: 0.7763\n",
      "Epoch 28/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.3885 - accuracy: 0.8930 - val_loss: 0.6473 - val_accuracy: 0.7753\n",
      "Epoch 29/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.3787 - accuracy: 0.8956 - val_loss: 0.6502 - val_accuracy: 0.7689\n",
      "Epoch 30/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.3668 - accuracy: 0.9061 - val_loss: 0.6262 - val_accuracy: 0.7787\n",
      "Epoch 31/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.3609 - accuracy: 0.9091 - val_loss: 0.7070 - val_accuracy: 0.7769\n",
      "Epoch 32/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.3554 - accuracy: 0.9110 - val_loss: 0.6661 - val_accuracy: 0.7863\n",
      "Epoch 33/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.3443 - accuracy: 0.9156 - val_loss: 0.7349 - val_accuracy: 0.7721\n",
      "Epoch 34/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.3445 - accuracy: 0.9170 - val_loss: 0.7524 - val_accuracy: 0.7787\n",
      "Epoch 35/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.3406 - accuracy: 0.9224 - val_loss: 0.7178 - val_accuracy: 0.7630\n",
      "Epoch 36/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.3376 - accuracy: 0.9215 - val_loss: 0.7296 - val_accuracy: 0.7769\n",
      "Epoch 37/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.3306 - accuracy: 0.9253 - val_loss: 0.7565 - val_accuracy: 0.7765\n",
      "Epoch 38/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.3198 - accuracy: 0.9314 - val_loss: 0.7246 - val_accuracy: 0.7797\n",
      "Epoch 39/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.3181 - accuracy: 0.9341 - val_loss: 0.8116 - val_accuracy: 0.7554\n",
      "Epoch 40/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.3117 - accuracy: 0.9342 - val_loss: 0.7108 - val_accuracy: 0.7755\n",
      "Epoch 41/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.3182 - accuracy: 0.9334 - val_loss: 0.7362 - val_accuracy: 0.7663\n",
      "Epoch 42/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.3103 - accuracy: 0.9371 - val_loss: 0.8314 - val_accuracy: 0.7604\n",
      "Epoch 43/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.3068 - accuracy: 0.9391 - val_loss: 0.9724 - val_accuracy: 0.7303\n",
      "Epoch 44/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.3105 - accuracy: 0.9398 - val_loss: 0.8594 - val_accuracy: 0.7644\n",
      "Epoch 45/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.2987 - accuracy: 0.9423 - val_loss: 0.8601 - val_accuracy: 0.7642\n",
      "Epoch 46/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.2992 - accuracy: 0.9430 - val_loss: 0.8465 - val_accuracy: 0.7723\n",
      "Epoch 47/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.2931 - accuracy: 0.9458 - val_loss: 0.9246 - val_accuracy: 0.7588\n",
      "Epoch 48/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.2919 - accuracy: 0.9465 - val_loss: 0.8391 - val_accuracy: 0.7791\n",
      "Epoch 49/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.2901 - accuracy: 0.9479 - val_loss: 0.9106 - val_accuracy: 0.7500\n",
      "Epoch 50/50\n",
      "14949/14949 [==============================] - 19s 1ms/sample - loss: 0.2949 - accuracy: 0.9445 - val_loss: 0.9076 - val_accuracy: 0.7638\n"
     ]
    }
   ],
   "source": [
    "permute = np.random.permutation(len(y))\n",
    "l = len(x)\n",
    "hist = model.fit(x[permute][:l], y[permute][:l], batch_size=64, epochs=50, validation_split=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:desi] *",
   "language": "python",
   "name": "conda-env-desi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
